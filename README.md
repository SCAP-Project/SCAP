# Credit Analysis Data Pipeline & Predictive Model

**Projeto de TCC / IniciaÃ§Ã£o CientÃ­fica** | Engenharia da ComputaÃ§Ã£o  
*Data de InÃ­cio: 06/2025* | *Status: Em Desenvolvimento*

## ğŸ¯ Objetivo
Desenvolver uma soluÃ§Ã£o de dados completa para anÃ¡lise de risco de crÃ©dito, integrando um Data Warehouse em PostgreSQL com um modelo preditivo baseado em Redes Neurais.

## ğŸ—ï¸ Arquitetura do Sistema
1. **ExtraÃ§Ã£o:** Dados histÃ³ricos de crÃ©dito de fontes simuladas/anonimizadas
2. **Armazenamento:** Data Warehouse em PostgreSQL com modelagem dimensional (Medalha)
3. **Processamento:** Pipeline de ETL em Python (Pandas, SQLAlchemy)
4. **ML Pipeline:** Feature engineering, treinamento e validaÃ§Ã£o (TensorFlow/Keras)
5. **VisualizaÃ§Ã£o:** Dashboard analÃ­tico (Streamlit - planejado)

## âš¡ Quick Start com GitHub Codespaces

### OpÃ§Ã£o 1: Criar Codespace
1. Abra https://github.com/[seu-usuario]/[seu-repo]
2. Clique em **Code** â†’ **Codespaces** â†’ **Create codespace on main**
3. Espere 3-5 minutos para configuraÃ§Ã£o automÃ¡tica
4. No terminal, inicie os containers:
   ```bash
   docker-compose up -d
   ```

### OpÃ§Ã£o 2: Desenvolvimento Local
PrÃ©-requisitos:
- Python 3.11+
- Docker e Docker Compose
- PostgreSQL Client (opcional)

Setup:
```bash
# Clone o repositÃ³rio
git clone [seu-repo-url]
cd TCC

# Copie o arquivo de ambiente
cp .env.example .env

# Instale as dependÃªncias
pip install -r requirements.txt
pip install -r ml/requirements.txt

# Inicie os containers
docker-compose up -d
```

## ğŸ“ Estrutura do Projeto

Veja [docs/estrutura-pasta.txt](docs/estrutura-pasta.txt) para detalhes completos.

Resumo das camadas:
```
project/
â”œâ”€â”€ data/               # Medalha Architecture
â”‚   â”œâ”€â”€ raw/           # Bronze: Dados brutos
â”‚   â”œâ”€â”€ trusted/       # Silver: Dados validados
â”‚   â””â”€â”€ refined/       # Gold: Dados para ML
â”œâ”€â”€ etl/                # Pipeline ETL
â”œâ”€â”€ ml/                 # Machine Learning
â”œâ”€â”€ sql/                # Scripts SQL
â””â”€â”€ docs/               # DocumentaÃ§Ã£o
```

## ğŸ› ï¸ Stack TecnolÃ³gica
- **Linguagens:** Python 3.11, SQL
- **Banco de Dados:** PostgreSQL 15
- **Data Processing:** Pandas, NumPy, SQLAlchemy
- **Machine Learning:** TensorFlow/Keras, Scikit-learn
- **ContainerizaÃ§Ã£o:** Docker, Docker Compose
- **Desenvolvimento:** Jupyter, GitHub Codespaces
- **Versionamento:** Git, GitHub

## ğŸ“Š Status Atual
- [x] DefiniÃ§Ã£o da arquitetura e modelagem dimensional do DW
- [x] ConfiguraÃ§Ã£o do ambiente (Docker, Codespaces)
- [x] ReorganizaÃ§Ã£o da estrutura do projeto
- [ ] ImplementaÃ§Ã£o dos scripts ETL
- [ ] Desenvolvimento do modelo de Rede Neural
- [ ] CriaÃ§Ã£o do dashboard com Streamlit
- [ ] Testes e CI/CD

## ğŸ”§ ConfiguraÃ§Ã£o RÃ¡pida

```bash
# Copiar ambiente
cp .env.example .env

# Instalar dependÃªncias
pip install -r requirements.txt

# Iniciar containers
docker-compose up -d

# Acessar banco de dados
psql -U postgres -h localhost -d financial_dw

# Jupyter
jupyter lab
```

## ğŸ“š DocumentaÃ§Ã£o Adicional
- [Estrutura do Projeto](docs/estrutura-pasta.txt)
- [Guia de ReorganizaÃ§Ã£o](docs/REORGANIZACAO.md)
- [Data Warehouse Docs](docs/db_docs/)

## ğŸš€ PrÃ³ximos Passos
1. Finalizar a camada de ingestÃ£o de dados
2. Implementar o pipeline de feature engineering
3. Treinar e validar o modelo preditivo
4. Configurar CI/CD com GitHub Actions

## ğŸ“– ReferÃªncias
- [Kimball Group - Data Warehouse Toolkit](https://www.kimballgroup.com/)
- [Medallion Architecture](https://www.databricks.com/blog/2022/06/24/introduction-medallion-architecture.html)
- [GitHub Codespaces](https://docs.github.com/en/codespaces)
- [PostgreSQL Docs](https://www.postgresql.org/docs/)
